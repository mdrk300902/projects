{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load CIFAR-10 (166 MB) [[8]]\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define model\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.fc = torch.nn.Linear(32*8*8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 32*8*8)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train for 2 epochs (demo)\n",
        "for epoch in range(2):\n",
        "    for inputs, labels in trainloader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/2 completed\")\n",
        "\n",
        "# Export to ONNX [[9]]\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    torch.randn(1, 3, 32, 32),\n",
        "    \"cifar10.onnx\",\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
        ")\n",
        "\n",
        "# Modified TensorRT section with dynamic shape support\n",
        "import tensorrt as trt\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(TRT_LOGGER)\n",
        "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
        "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "# Parse ONNX model\n",
        "with open(\"cifar10.onnx\", \"rb\") as f:\n",
        "    if not parser.parse(f.read()):\n",
        "        print(\"ONNX parsing errors:\")\n",
        "        for error in range(parser.num_errors):\n",
        "            print(parser.get_error(error))\n",
        "        exit(1)\n",
        "\n",
        "# Configure TensorRT with dynamic shapes\n",
        "config = builder.create_builder_config()\n",
        "config.set_flag(trt.BuilderFlag.FP16)\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB\n",
        "\n",
        "# Create optimization profile for dynamic batch size\n",
        "profile = builder.create_optimization_profile()\n",
        "input_name = network.get_input(0).name\n",
        "input_shape = network.get_input(0).shape\n",
        "\n",
        "# Set min/opt/max dimensions for dynamic axes (batch size in this case)\n",
        "profile.set_shape(\n",
        "    input_name,\n",
        "    min=(1, 3, 32, 32),  # Minimum batch size\n",
        "    opt=(32, 3, 32, 32),  # Optimal batch size\n",
        "    max=(64, 3, 32, 32)   # Maximum batch size\n",
        ")\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# Build engine\n",
        "serialized_engine = builder.build_serialized_network(network, config)\n",
        "\n",
        "if not serialized_engine:\n",
        "    print(\"Engine build failed!\")\n",
        "    exit(1)\n",
        "\n",
        "# Deserialize and save\n",
        "runtime = trt.Runtime(TRT_LOGGER)\n",
        "engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
        "\n",
        "with open(\"cifar10.engine\", \"wb\") as f:\n",
        "    f.write(serialized_engine)\n",
        "\n",
        "print(\"Engine build successful!\")"
      ],
      "metadata": {
        "id": "xDoe7zOd9HDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/project/app.py\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit  # Automatically initialize CUDA driver\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load TensorRT engine\n",
        "def load_engine():\n",
        "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "    with open(\"cifar10.engine\", \"rb\") as f:\n",
        "        runtime = trt.Runtime(TRT_LOGGER)\n",
        "        return runtime.deserialize_cuda_engine(f.read())\n",
        "\n",
        "engine = load_engine()\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "# Allocate memory\n",
        "h_input = cuda.pagelocked_empty(trt.volume(context.get_binding_shape(0)), dtype=np.float32)\n",
        "h_output = cuda.pagelocked_empty(trt.volume(context.get_binding_shape(1)), dtype=np.float32)\n",
        "d_input = cuda.mem_alloc(h_input.nbytes)\n",
        "d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "stream = cuda.Stream()\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    img = np.frombuffer(await file.read(), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img, (32, 32)).astype(np.float32)\n",
        "    img = np.transpose(img, (2, 0, 1)) / 255.0\n",
        "    np.copyto(h_input, img.ravel())\n",
        "\n",
        "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
        "    context.execute_async_v2(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
        "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "    stream.synchronize()\n",
        "\n",
        "    return {\"class\": int(np.argmax(h_output))}"
      ],
      "metadata": {
        "id": "7CelLWAk-jrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/project/Dockerfile\n",
        "FROM nvcr.io/nvidia/pytorch:23.12-py3\n",
        "\n",
        "WORKDIR /app\n",
        "COPY . .\n",
        "\n",
        "RUN apt-get update && apt-get install -y libgl1-mesa-glx\n",
        "RUN pip install --no-cache-dir fastapi uvicorn numpy opencv-python-headless pycuda tensorrt\n",
        "\n",
        "EXPOSE 8000\n",
        "\n",
        "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
      ],
      "metadata": {
        "id": "jnOiTn_H-juo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBqKSwG0-jwu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}