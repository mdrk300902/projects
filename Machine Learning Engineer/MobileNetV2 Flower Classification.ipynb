{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNzbvlduM0Hkg1ySTkj9M9g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"H7ZUv9Vhwp3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================\n","# Environment Setup\n","# ==========================================\n","print(\"Setting up environment...\")\n","\n","# Install required packages\n","!pip install -Uqq tensorflow tensorflow-datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C23rmuhFwHVF","executionInfo":{"status":"ok","timestamp":1744910338509,"user_tz":-330,"elapsed":3566,"user":{"displayName":"TensorFlow","userId":"02052554466945344371"}},"outputId":"7853f2e3-c7f5-4111-c5c1-7e46b0a14364"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up environment...\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YA0EHZdguthG","executionInfo":{"status":"ok","timestamp":1744910717026,"user_tz":-330,"elapsed":148748,"user":{"displayName":"TensorFlow","userId":"02052554466945344371"}},"outputId":"fba739b5-3836-494e-fd41-4b516ec15d9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.19.0\n","Environment setup complete.\n","\n","Setting configuration parameters...\n","Using MobileNetV2 with image size (128, 128)\n","Batch size: 16, Epochs: 20\n","Checkpoint path: /content/drive/MyDrive/flower_classifier.keras\n","\n","Preparing dataset...\n","Loading dataset...\n","Creating data pipelines...\n","Training samples: 2936\n","Validation samples: 367\n","Test samples: 367\n","Data preparation complete.\n","\n","Building model...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_128            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m6,405\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_128            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,405</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,264,389\u001b[0m (8.64 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,264,389</span> (8.64 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,405\u001b[0m (25.02 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,405</span> (25.02 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Model built successfully.\n","\n","Configuring training...\n","Training configuration complete.\n","\n","Starting training...\n","Epoch 1/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 120ms/step - accuracy: 0.6214 - loss: 0.9922 - val_accuracy: 0.8365 - val_loss: 0.4186\n","Epoch 2/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.8528 - loss: 0.4142 - val_accuracy: 0.8638 - val_loss: 0.3694\n","Epoch 3/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.8765 - loss: 0.3463 - val_accuracy: 0.8801 - val_loss: 0.3247\n","Epoch 4/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8820 - loss: 0.3043 - val_accuracy: 0.9046 - val_loss: 0.3207\n","Epoch 5/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.9038 - loss: 0.2707 - val_accuracy: 0.8719 - val_loss: 0.3366\n","Epoch 6/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.9297 - loss: 0.2271 - val_accuracy: 0.8883 - val_loss: 0.3230\n","Epoch 7/20\n","\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - accuracy: 0.9269 - loss: 0.2173 - val_accuracy: 0.9019 - val_loss: 0.3259\n","\n","Training complete.\n","\n","Evaluating model...\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - accuracy: 0.8572 - loss: 0.4324\n","\n","Test accuracy: 0.8856\n","Test loss: 0.3708\n","\n","Cleaning up resources...\n","Cleanup complete.\n"]}],"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow.keras import layers, models\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(\"Environment setup complete.\\n\")\n","\n","# ==========================================\n","# Configuration\n","# ==========================================\n","print(\"Setting configuration parameters...\")\n","\n","# Dataset parameters\n","DATASET_NAME = 'tf_flowers'\n","NUM_CLASSES = 5\n","IMG_SIZE = (128, 128)\n","BATCH_SIZE = 16\n","BUFFER_SIZE = 1000\n","\n","# Model parameters\n","BASE_MODEL = tf.keras.applications.MobileNetV2\n","FREEZE_LAYERS = True\n","INPUT_SHAPE = IMG_SIZE + (3,)\n","\n","# Training parameters\n","INITIAL_EPOCHS = 20\n","PATIENCE = 3\n","VALIDATION_SPLIT = 0.2\n","SAVE_PATH = \"/content/drive/MyDrive/flower_classifier.keras\"\n","\n","print(f\"Using {BASE_MODEL.__name__} with image size {IMG_SIZE}\")\n","print(f\"Batch size: {BATCH_SIZE}, Epochs: {INITIAL_EPOCHS}\")\n","print(f\"Checkpoint path: {SAVE_PATH}\\n\")\n","\n","# ==========================================\n","# Data Preparation\n","# ==========================================\n","print(\"Preparing dataset...\")\n","\n","def preprocess_image(image, label):\n","    # Resize and normalize images\n","    image = tf.image.resize(image, IMG_SIZE)\n","    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n","    return image, label\n","\n","def data_augment(image, label):\n","    # Using only native TF operations\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_brightness(image, max_delta=0.2)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n","    # Random 90-degree rotations\n","    if tf.random.uniform(()) > 0.5:\n","        image = tf.image.rot90(image)\n","    return image, label\n","\n","# Load dataset\n","print(\"Loading dataset...\")\n","(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n","    name=DATASET_NAME,\n","    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n","    as_supervised=True,\n","    with_info=True\n",")\n","\n","# Create pipelines\n","print(\"Creating data pipelines...\")\n","train_ds = ds_train.map(data_augment, num_parallel_calls=tf.data.AUTOTUNE)\n","train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","val_ds = ds_validation.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","test_ds = ds_test.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","\n","print(f\"Training samples: {ds_info.splits['train'].num_examples * 0.8:.0f}\")\n","print(f\"Validation samples: {ds_info.splits['train'].num_examples * 0.1:.0f}\")\n","print(f\"Test samples: {ds_info.splits['train'].num_examples * 0.1:.0f}\")\n","print(\"Data preparation complete.\\n\")\n","\n","# ==========================================\n","# Model Configuration\n","# ==========================================\n","print(\"Building model...\")\n","\n","# Create base model\n","base_model = BASE_MODEL(\n","    input_shape=INPUT_SHAPE,\n","    include_top=False,\n","    weights='imagenet'\n",")\n","\n","if FREEZE_LAYERS:\n","    base_model.trainable = False\n","\n","# Build classification head\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(NUM_CLASSES, activation='softmax')\n","])\n","\n","model.summary()\n","print(\"\\nModel built successfully.\\n\")\n","\n","# ==========================================\n","# Training Setup\n","# ==========================================\n","print(\"Configuring training...\")\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss',\n","        patience=PATIENCE,\n","        restore_best_weights=True\n","    ),\n","    tf.keras.callbacks.ModelCheckpoint(\n","        filepath=SAVE_PATH,\n","        save_best_only=True,\n","        monitor='val_accuracy'\n","    )\n","]\n","\n","print(\"Training configuration complete.\\n\")\n","\n","# ==========================================\n","# Training Execution\n","# ==========================================\n","print(\"Starting training...\")\n","\n","history = model.fit(\n","    train_ds,\n","    epochs=INITIAL_EPOCHS,\n","    validation_data=val_ds,\n","    callbacks=callbacks\n",")\n","\n","print(\"\\nTraining complete.\\n\")\n","\n","# ==========================================\n","# Evaluation\n","# ==========================================\n","print(\"Evaluating model...\")\n","\n","model = tf.keras.models.load_model(SAVE_PATH)\n","test_loss, test_acc = model.evaluate(test_ds)\n","print(f\"\\nTest accuracy: {test_acc:.4f}\")\n","print(f\"Test loss: {test_loss:.4f}\")\n","\n","# ==========================================\n","# Resource Cleanup\n","# ==========================================\n","print(\"\\nCleaning up resources...\")\n","\n","del ds_train, ds_validation, ds_test\n","del train_ds, val_ds, test_ds\n","tf.keras.backend.clear_session()\n","\n","print(\"Cleanup complete.\")"]},{"cell_type":"code","source":[],"metadata":{"id":"UTVJko9HvOAa"},"execution_count":null,"outputs":[]}]}